{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teenarai/DL_with_python/keras_dl_with_python/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(d_ff, activation=\"relu\")\n",
    "        self.dense2 = tf.keras.layers.Dense(d_model) # no activation\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.dense2(self.dense1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((2, 6, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = FNN(d_model = 512, d_ff=2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FNN name=fnn, built=False>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ffn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6, 512), dtype=float32, numpy=\n",
       "array([[[-8.35852772e-02, -4.55801524e-02,  4.02150929e-01, ...,\n",
       "         -2.74178863e-01, -7.84548998e-01,  1.41986385e-01],\n",
       "        [-1.07644871e-01,  1.74158692e-01,  4.90542978e-01, ...,\n",
       "         -1.23695202e-01, -5.29394865e-01, -1.69134632e-01],\n",
       "        [-8.01319331e-02,  2.08575070e-01,  3.63009125e-01, ...,\n",
       "          1.83665663e-01, -2.78570652e-01, -6.65538758e-02],\n",
       "        [ 4.61086631e-04,  1.92499086e-01,  1.86467752e-01, ...,\n",
       "         -3.53020668e-01, -4.32115048e-01, -1.57496244e-01],\n",
       "        [ 3.12806293e-02,  1.00791916e-01,  2.11452082e-01, ...,\n",
       "         -3.02582026e-01, -2.43920624e-01, -7.78396949e-02],\n",
       "        [-4.53638464e-01,  1.58476144e-01,  4.48831052e-01, ...,\n",
       "         -3.92302752e-01, -3.92625391e-01, -1.62144527e-01]],\n",
       "\n",
       "       [[-1.75863981e-01,  4.49056178e-02,  2.20573321e-01, ...,\n",
       "         -1.16870470e-01, -3.56314421e-01, -1.48955151e-01],\n",
       "        [-2.19064087e-01,  1.72210768e-01,  4.33883905e-01, ...,\n",
       "         -6.03727698e-02, -6.43185139e-01, -3.46296668e-01],\n",
       "        [-4.67588067e-01,  2.20939696e-01,  2.75526077e-01, ...,\n",
       "         -3.56402487e-01, -5.00661314e-01, -1.37645483e-01],\n",
       "        [-5.00795022e-02,  3.16914856e-01,  3.56036216e-01, ...,\n",
       "         -4.30964738e-01, -5.28922856e-01, -5.66126481e-02],\n",
       "        [-8.04098248e-02, -6.11513853e-04,  6.21164203e-01, ...,\n",
       "         -2.81897187e-01, -3.11587811e-01,  7.23634809e-02],\n",
       "        [-3.15265566e-01,  3.50500271e-02,  3.82395148e-01, ...,\n",
       "          2.18218639e-02, -4.45078373e-01,  1.27768934e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot-Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "\n",
    "    \"\"\" \n",
    "    Q, K, V must have shape: (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "\n",
    "    dk = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "    print(f\"Depth of key: {dk}\")\n",
    "\n",
    "    scores = tf.matmul(Q, K, transpose_b=True)\n",
    "    print(f\"Scores: {scores}\")\n",
    "    scores = scores / tf.math.sqrt(dk)\n",
    "    print(f\"Scores after scaling: {scores}\")\n",
    "\n",
    "    if mask is not None:\n",
    "        scores += (mask * -1e9)\n",
    "    print(f\"Scores after masking: {scores}\")\n",
    "\n",
    "    weights = tf.nn.softmax(scores, axis=-1)\n",
    "    output = tf.matmul(weights, V)\n",
    "\n",
    "    return output, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.13192785 0.06096387 0.8971474  0.96041584]\n",
      "   [0.48912    0.02534592 0.26345062 0.5428848 ]\n",
      "   [0.5472523  0.32141066 0.9289235  0.4597925 ]]\n",
      "\n",
      "  [[0.3177898  0.9874586  0.3536203  0.48786688]\n",
      "   [0.98315907 0.67036283 0.6021272  0.7656299 ]\n",
      "   [0.03581572 0.44106424 0.873765   0.9436176 ]]]\n",
      "\n",
      "\n",
      " [[[0.26351404 0.94685376 0.5665641  0.14089334]\n",
      "   [0.2653072  0.81594086 0.62459075 0.30572188]\n",
      "   [0.7382891  0.04632449 0.03618693 0.91745996]]\n",
      "\n",
      "  [[0.09616554 0.69231737 0.3298658  0.47897792]\n",
      "   [0.01625562 0.74581444 0.7972766  0.41946185]\n",
      "   [0.7451682  0.6699667  0.12812448 0.24165046]]]], shape=(2, 2, 3, 4), dtype=float32)\n",
      "Depth of key: 4.0\n",
      "Scores: [[[[1.0587585  1.0833192  1.4869896 ]\n",
      "   [0.6707403  0.96783924 0.70198315]\n",
      "   [1.2723552  1.1933345  1.3883924 ]]\n",
      "\n",
      "  [[1.1699665  0.7106823  1.3150005 ]\n",
      "   [1.3136827  0.97592485 1.8117888 ]\n",
      "   [0.5738417  1.1524079  1.0484695 ]]]\n",
      "\n",
      "\n",
      " [[[1.2551565  0.9133693  1.2422342 ]\n",
      "   [1.2884903  0.9173759  1.2582126 ]\n",
      "   [1.4167737  1.122716   0.73152447]]\n",
      "\n",
      "  [[0.66337264 1.292882   0.7822091 ]\n",
      "   [0.72113407 1.5085158  0.8009421 ]\n",
      "   [0.9995192  0.9968003  0.6447993 ]]]]\n",
      "Scores after scaling: [[[[0.52937925 0.5416596  0.7434948 ]\n",
      "   [0.33537015 0.48391962 0.35099158]\n",
      "   [0.6361776  0.59666723 0.6941962 ]]\n",
      "\n",
      "  [[0.5849832  0.35534114 0.65750027]\n",
      "   [0.65684134 0.48796242 0.9058944 ]\n",
      "   [0.28692085 0.57620394 0.5242348 ]]]\n",
      "\n",
      "\n",
      " [[[0.62757826 0.45668465 0.6211171 ]\n",
      "   [0.64424515 0.45868796 0.6291063 ]\n",
      "   [0.70838684 0.561358   0.36576223]]\n",
      "\n",
      "  [[0.33168632 0.646441   0.39110455]\n",
      "   [0.36056703 0.7542579  0.40047106]\n",
      "   [0.4997596  0.49840015 0.32239965]]]]\n",
      "Scores after masking: [[[[0.52937925 0.5416596  0.7434948 ]\n",
      "   [0.33537015 0.48391962 0.35099158]\n",
      "   [0.6361776  0.59666723 0.6941962 ]]\n",
      "\n",
      "  [[0.5849832  0.35534114 0.65750027]\n",
      "   [0.65684134 0.48796242 0.9058944 ]\n",
      "   [0.28692085 0.57620394 0.5242348 ]]]\n",
      "\n",
      "\n",
      " [[[0.62757826 0.45668465 0.6211171 ]\n",
      "   [0.64424515 0.45868796 0.6291063 ]\n",
      "   [0.70838684 0.561358   0.36576223]]\n",
      "\n",
      "  [[0.33168632 0.646441   0.39110455]\n",
      "   [0.36056703 0.7542579  0.40047106]\n",
      "   [0.4997596  0.49840015 0.32239965]]]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_heads = 2\n",
    "seq_len = 3\n",
    "depth = 4\n",
    "\n",
    "Q = tf.random.uniform((batch_size, num_heads, seq_len, depth))\n",
    "K = tf.random.uniform((batch_size, num_heads, seq_len, depth))\n",
    "V = tf.random.uniform((batch_size, num_heads, seq_len, depth))\n",
    "\n",
    "print(Q)\n",
    "\n",
    "output, weights = scaled_dot_product_attention(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 2, 3, 4]), TensorShape([2, 2, 3, 3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3, 4), dtype=float32, numpy=\n",
       "array([[[[0.73807085, 0.729236  , 0.6344718 , 0.29381454],\n",
       "         [0.7079821 , 0.7370317 , 0.64335686, 0.29303288],\n",
       "         [0.7290781 , 0.7360657 , 0.6410845 , 0.28820172]],\n",
       "\n",
       "        [[0.6396093 , 0.41814047, 0.5314377 , 0.42670676],\n",
       "         [0.6338031 , 0.40491855, 0.51910657, 0.40121862],\n",
       "         [0.570755  , 0.3676917 , 0.49975106, 0.37539488]]],\n",
       "\n",
       "\n",
       "       [[[0.39296493, 0.38775754, 0.43081352, 0.38847193],\n",
       "         [0.3944624 , 0.38647643, 0.4304597 , 0.38673842],\n",
       "         [0.3844385 , 0.39777744, 0.46474037, 0.4072292 ]],\n",
       "\n",
       "        [[0.32698074, 0.48194206, 0.7055749 , 0.5351881 ],\n",
       "         [0.32080248, 0.47820938, 0.6978057 , 0.5394257 ],\n",
       "         [0.37857187, 0.51062906, 0.7075405 , 0.53352463]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0.30758616, 0.3113867 , 0.38102722],\n",
       "         [0.31487194, 0.36529875, 0.31982931],\n",
       "         [0.3310168 , 0.31819323, 0.35079002]],\n",
       "\n",
       "        [[0.34842852, 0.27693728, 0.37463424],\n",
       "         [0.31975225, 0.2700663 , 0.4101814 ],\n",
       "         [0.2775227 , 0.37062317, 0.35185412]]],\n",
       "\n",
       "\n",
       "       [[[0.35255077, 0.297169  , 0.35028023],\n",
       "         [0.35516202, 0.29501227, 0.34982577],\n",
       "         [0.38862512, 0.33548805, 0.27588677]],\n",
       "\n",
       "        [[0.29144812, 0.39926153, 0.3092903 ],\n",
       "         [0.28383666, 0.42077142, 0.2953919 ],\n",
       "         [0.35259444, 0.35211542, 0.29529017]]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_dl_with_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
